{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful modules for notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdne.conf import DATASETDIR\n",
    "from pathlib import Path\n",
    "from tqdne.dataset import H5Dataset, RandomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import UNet1DModel\n",
    "from diffusers import DDPMScheduler\n",
    "from tqdne.diffusers import DDPMPipeline1DCond\n",
    "from tqdne.lightning import LightningDDMP\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from tqdne.conf import OUTPUTDIR\n",
    "\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create very simple synthetic dataset\n",
    "\n",
    "t = (5501 // 16) * 16\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# path_train = DATASETDIR / Path(\"data_train.h5\")\n",
    "# path_test = DATASETDIR / Path(\"data_test.h5\")\n",
    "# train_dataset = H5Dataset(path_train, cut=t)\n",
    "# test_dataset = H5Dataset(path_test, cut=t)\n",
    "\n",
    "train_dataset = RandomDataset(1024*8)\n",
    "test_dataset = RandomDataset(512)\n",
    "\n",
    "channels = train_dataset[0][0].shape[0]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res, high_res = train_dataset[0]\n",
    "\n",
    "low_res.shape, high_res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100\n",
    "time = np.arange(0, t)/fs\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time ,low_res[0].numpy(), 'b', label=\"Input\")\n",
    "plt.plot(time, high_res[0].numpy(), 'r', label=\"Target\")\n",
    "plt.xlim(1, 5)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_low, batch_high = next(iter(train_loader))\n",
    "batch_low.shape, batch_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "# Unet parameters\n",
    "unet_params = {\n",
    "    \"sample_size\":t,\n",
    "    \"in_channels\":channels, \n",
    "    \"out_channels\":channels,\n",
    "    \"block_out_channels\":  (32, 64, 128),\n",
    "    \"down_block_types\": ('DownBlock1D', 'DownBlock1D', 'AttnDownBlock1D'),\n",
    "    \"up_block_types\": ('AttnUpBlock1D', 'UpBlock1D', 'UpBlock1D'),\n",
    "    \"mid_block_type\": 'UNetMidBlock1D',\n",
    "    \"extra_in_channels\" : channels \n",
    "}\n",
    "\n",
    "scheduler_params = {\n",
    "    \"beta_schedule\": \"linear\",\n",
    "    \"beta_start\": 0.0001,\n",
    "    \"beta_end\": 0.02,\n",
    "    \"num_train_timesteps\": 1000,\n",
    "}\n",
    "\n",
    "optimizer_params = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"lr_warmup_steps\": 500,\n",
    "    \"n_train\": len(train_dataset) // batch_size,\n",
    "    \"seed\": 0,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_epochs\": max_epochs,\n",
    "}\n",
    "\n",
    "trainer_params = {\n",
    "    # trainer parameters\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"precision\": \"32-true\",  \n",
    "    # Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\n",
    "    # 16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\n",
    "    # Can be used on CPU, GPU, TPUs, HPUs or IPUs.\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"devices\": \"auto\",\n",
    "    \"num_nodes\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = UNet1DModel(**unet_params)\n",
    "net.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_inputs(low_res, high_res):\n",
    "    \"\"\"Build Unet inputs from low and high resolution data.\"\"\"\n",
    "    return torch.cat((low_res, high_res), dim=1)\n",
    "high_resn = torch.rand(batch_size, 1,t)\n",
    "\n",
    "inputs = to_inputs(batch_low, high_resn)\n",
    "timesteps = torch.LongTensor([150]*batch_size)\n",
    "print(inputs.shape)\n",
    "assert net(inputs, timesteps).sample.shape == batch_high.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler(**scheduler_params)\n",
    "scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_high.shape)\n",
    "timesteps = torch.LongTensor([50]*batch_size)\n",
    "noisy_sig = scheduler.add_noise(batch_high, noise, timesteps)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time, noisy_sig[0,0].numpy(), 'b', label=\"noisy\")\n",
    "plt.plot(time, batch_high[0,0].numpy(), 'r',  label=\"original\")\n",
    "plt.xlim(1, 5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is probably wrong because of the conditioning\n",
    "# import tqdm\n",
    "\n",
    "# def sample(noise):\n",
    "#     sample = noise\n",
    "#     for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "#         # 1. predict noise residual\n",
    "#         with torch.no_grad():\n",
    "#             residual = net(sample, t).sample\n",
    "#         # 2. compute less noisy image and set x_t -> x_t-1\n",
    "#         sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "#     return sample\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# sample = train_dataset[0]\n",
    "# sig = sample.unsqueeze(0)\n",
    "# print(sig.shape)\n",
    "# noise = torch.randn(sig[:,:1].shape)\n",
    "# timesteps = torch.LongTensor([150])\n",
    "# noisy_sig = scheduler.add_noise(sig[:,:1], noise, timesteps)\n",
    "# noisy_sig = torch.concat([noisy_sig, sig[:,1:]], dim=1)\n",
    "# noise_pred = net(noisy_sig, timesteps).sample\n",
    "# loss = F.mse_loss(noise_pred, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DDPMPipeline1DCond(net, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(low_res, pipeline):\n",
    "#     # Sample some signaol from random noise (this is the backward diffusion process).\n",
    "#     sig = pipeline(\n",
    "#         low_res = low_res,\n",
    "#         generator=torch.manual_seed(optimizer_params[\"seed\"]),\n",
    "#     ).audios\n",
    "\n",
    "#     return sig\n",
    "\n",
    "# batch_low, batch_high = next(iter(train_loader))\n",
    "# gen_high = evaluate(batch_low, pipeline)\n",
    "\n",
    "# plt.plot(time, batch_high[0,0].numpy(), 'b', label=\"high res\")\n",
    "# plt.plot(time, batch_low[0,0].numpy(), 'r', label=\"low res\")\n",
    "# plt.plot(time, gen_high[0,0].numpy(), 'g', alpha=0.5, label=\"generated\")\n",
    "# plt.legend()\n",
    "# plt.xlim(1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningDDMP(net, scheduler, optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '1D-UNET'\n",
    "\n",
    "# 1. Wandb Logger\n",
    "wandb_logger = WandbLogger() # add project='projectname' to log to a specific project\n",
    "\n",
    "# 2. Learning Rate Logger\n",
    "lr_logger = LearningRateMonitor()\n",
    "# 3. Set Early Stopping\n",
    "early_stopping = EarlyStopping('val_loss', mode='min', patience=5)\n",
    "# 4. saves checkpoints to 'model_path' whenever 'val_loss' has a new min\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=OUTPUTDIR / Path(name), filename='{name}_{epoch}-{val_loss:.2f}',\n",
    "                                      monitor='val_loss', mode='min', save_top_k=5)\n",
    "\n",
    "(OUTPUTDIR/Path(name)).mkdir(parents=True, exist_ok=True)\n",
    "# Define Trainer\n",
    "trainer = pl.Trainer(**trainer_params, logger=wandb_logger, callbacks=[lr_logger, early_stopping, checkpoint_callback], \n",
    "                     default_root_dir=OUTPUTDIR/Path(name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res, high_res = next(iter(test_loader))\n",
    "reconstructed = model.evaluate(low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, t = reconstructed.shape\n",
    "fs = 100\n",
    "time = np.arange(0, t)/fs\n",
    "i = 0\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(time ,low_res[i,0].cpu().numpy(), 'b', label=\"Input\")\n",
    "plt.plot(time, high_res[i,0].cpu().numpy(), 'r', label=\"Target\")\n",
    "plt.plot(time, reconstructed[i,0].cpu().numpy(), 'g', alpha=0.5, label=\"Reconstructed\")\n",
    "plt.xlim(1, 5)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqdne-GZO51An4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
